package com.freshworks.scraper.web;

import com.freshworks.scraper.llm.LLMClient;
import com.freshworks.scraper.llm.LLMException;
import com.freshworks.scraper.config.AppConfig;
import com.freshworks.scraper.model.ScrapeJob;
import com.freshworks.scraper.service.JobService;

import java.util.Map;
import jakarta.validation.Valid;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.http.HttpStatus;
import org.springframework.http.MediaType;
import org.springframework.http.ResponseEntity;
import org.springframework.validation.annotation.Validated;
import org.springframework.web.bind.annotation.*;

import java.time.Duration;
import java.time.LocalDateTime;

/**
 * REST API controller for the API documentation scraper.
 */
@RestController
@RequestMapping("/api/v1/scraper")
@Validated
@CrossOrigin(origins = "*")
public class ApiScraperController {
    
    private static final Logger logger = LoggerFactory.getLogger(ApiScraperController.class);
    
    private final AppConfig appConfig;
    private final JobService jobService;
    private final LLMClient llmClient;
    
    public ApiScraperController(AppConfig appConfig, JobService jobService) {
        this.appConfig = appConfig;
        this.jobService = jobService;
        // Initialize LLM client for humorous messages (use token from config)
        this.llmClient = new LLMClient(appConfig.getLLMApiToken());
    }
    
    /**
     * POST /api/v1/scraper/scrape
     * 
     * Queues a scraping job and returns immediately with a job ID.
     * The actual scraping happens asynchronously.
     * 
     * @param request The scrape request containing URL and options
     * @return JobResponse with job ID
     */
    @PostMapping(value = "/scrape", produces = MediaType.APPLICATION_JSON_VALUE)
    public ResponseEntity<JobResponse> scrape(@Valid @RequestBody ScrapeRequest request) {
        logger.info("Scrape job request received for URL: {}", request.getUrl());
        
        try {
            // Determine LLM token (from request, environment, or config)
            String llmToken = determineLlmToken(request.getLlmToken());
            
            // Create and queue the job
            ScrapeJob job = jobService.createJob(
                    request.getUrl(),
                    request.isUsePlaywright(),
                    llmToken,
                    request.getAdditionalUrls()
            );
            
            logger.info("Scrape job {} queued for URL: {}", job.getJobId(), request.getUrl());
            
            return ResponseEntity.status(HttpStatus.ACCEPTED)
                    .body(JobResponse.queued(
                            job.getJobId(),
                            "Scraping job queued successfully. Use /scrape/" + job.getJobId() + " to check status."
                    ));
            
        } catch (Exception e) {
            logger.error("Failed to queue scraping job", e);
            return ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR)
                    .body(JobResponse.failed(null, "Failed to queue job: " + e.getMessage()));
        }
    }
    
    /**
     * GET /api/v1/scraper/scrape/{jobId}
     * 
     * Retrieves the status and results of a scraping job.
     * If the job is still processing, returns a humorous message generated by LLM.
     * 
     * @param jobId The job ID returned from the /scrape endpoint
     * @return JobResponse with status and results (if completed) or humorous message (if pending)
     */
    @GetMapping(value = "/scrape/{jobId}", produces = MediaType.APPLICATION_JSON_VALUE)
    public ResponseEntity<JobResponse> getJobStatus(@PathVariable String jobId) {
        logger.info("Job status request for job ID: {}", jobId);
        
        ScrapeJob job = jobService.getJob(jobId);
        
        if (job == null) {
            logger.warn("Job {} not found", jobId);
            return ResponseEntity.status(HttpStatus.NOT_FOUND)
                    .body(JobResponse.notFound(jobId));
        }
        
        // If job is completed or failed, return the results
        if (job.getStatus() == ScrapeJob.Status.COMPLETED) {
            logger.info("Job {} completed, returning results", jobId);
            return ResponseEntity.ok(JobResponse.completed(job));
        }
        
        if (job.getStatus() == ScrapeJob.Status.FAILED) {
            logger.warn("Job {} failed", jobId);
            return ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR)
                    .body(JobResponse.failed(jobId, job.getErrorMessage()));
        }
        
        // Job is still processing (QUEUED or PROCESSING)
        // Generate a humorous message using LLM
        logger.info("Job {} is still processing, generating humorous message", jobId);
        String humorousMessage = generateHumorousMessage(job);
        
        return ResponseEntity.status(HttpStatus.ACCEPTED)
                .body(JobResponse.pending(jobId, humorousMessage));
    }
    
    /**
     * Generates a short humorous message about the job status using LLM.
     * Uses a shorter timeout (10 seconds) since this is non-critical.
     */
    private String generateHumorousMessage(ScrapeJob job) {
        try {
            long elapsedSeconds = Duration.between(job.getCreatedAt(), LocalDateTime.now()).getSeconds();
            String progressMessage = job.getProgressMessage() != null ? job.getProgressMessage() : "processing";
            
            String systemPrompt = "You are a witty assistant. Generate a VERY SHORT humorous message " +
                    "(ONE sentence, max 15 words) about waiting for an API documentation scraping job. " +
                    "Make it brief, fun, and reassuring. No emojis unless specifically requested.";
            
            String userPrompt = String.format(
                    "Job running %d seconds. Status: %s. Generate ONE short, witty sentence " +
                    "(max 15 words) that the job is still working. Be concise and humorous.",
                    elapsedSeconds,
                    progressMessage
            );
            
            // Use shorter timeout (10 seconds) for non-critical humorous messages
            String llmResponse = llmClient.call(systemPrompt, userPrompt, 10);
            
            // Clean up any markdown formatting from LLM response
            String cleaned = llmResponse.trim()
                    .replaceAll("^\"|\"$", "") // Remove quotes
                    .replaceAll("^```[\\w]*\n?|\n?```$", "") // Remove code blocks
                    .trim();
            
            // Ensure it's short - truncate if too long
            if (cleaned.length() > 120) {
                cleaned = cleaned.substring(0, 117) + "...";
            }
            
            return cleaned;
                    
        } catch (LLMException e) {
            // Log at debug level since this is non-critical and failures are expected
            logger.debug("Failed to generate humorous message (timeout expected), using fallback: {}", e.getMessage());
            // Fallback message if LLM call fails or times out
            long elapsedSeconds = Duration.between(job.getCreatedAt(), LocalDateTime.now()).getSeconds();
            return String.format(
                    "Still scraping! %d seconds and counting...",
                    elapsedSeconds
            );
        }
    }
    
    /**
     * GET /api/v1/scraper/health
     * 
     * Health check endpoint.
     */
    @GetMapping("/health")
    public ResponseEntity<java.util.Map<String, Object>> health() {
        logger.info("Health check requested");
        
        java.util.Map<String, Object> status = new java.util.HashMap<>();
        status.put("status", "UP");
        status.put("timestamp", LocalDateTime.now());
        status.put("llmConfigured", appConfig.getLLMApiToken() != null);
        
        return ResponseEntity.ok(status);
    }
    
    /**
     * GET /api/v1/scraper/config
     * 
     * Returns current configuration (without sensitive data).
     */
    @GetMapping("/config")
    public ResponseEntity<Map<String, Object>> config() {
        Map<String, Object> config = new java.util.HashMap<>();
        config.put("llmConfigured", appConfig.getLLMApiToken() != null);
        config.put("llmApiUrl", appConfig.getLLMApiUrl());
        config.put("llmModel", appConfig.getLLMApiModel());
        config.put("version", "1.0.0");
        
        return ResponseEntity.ok(config);
    }
    
    /**
     * GET /api/v1/scraper/jobs/stats
     * 
     * Returns statistics about current jobs (for monitoring).
     */
    @GetMapping("/jobs/stats")
    public ResponseEntity<Map<String, Object>> getJobStatistics() {
        Map<String, Object> stats = jobService.getJobStatistics();
        return ResponseEntity.ok(stats);
    }
    
    /**
     * Determines which LLM token to use based on priority:
     * 1. Request parameter
     * 2. Environment variable
     * 3. Config file
     */
    private String determineLlmToken(String requestToken) {
        if (requestToken != null && !requestToken.isEmpty()) {
            return requestToken;
        }
        
        String envToken = System.getenv("LLM_API_TOKEN");
        if (envToken != null && !envToken.isEmpty()) {
            return envToken;
        }
        
        return appConfig.getLLMApiToken();
    }
}


